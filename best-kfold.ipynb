{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "combined-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os, sys\n",
    "from importlib import import_module\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import SGD, Adam, AdamW, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from glob import glob\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "# from model import *\n",
    "import timm\n",
    "import time\n",
    "from adamp import AdamP\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정\n",
    "    \n",
    "    Args:\n",
    "        seed : seed 정수 값\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "seed_everything(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-synthetic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stunning-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = 'input/data/train/images'\n",
    "label_path = 'input/data/train/train.csv'\n",
    "\n",
    "model_name = 'efficientnet_b3_pruned'\n",
    "use_pretrained = True\n",
    "freeze_backbone = False # classifier head 이 외 부분을 업데이트되지 않게 할 것인지 여부\n",
    "\n",
    "val_split = 0.2\n",
    "batch_size = 64\n",
    "num_workers = 3\n",
    "num_classes = 6\n",
    "\n",
    "num_epochs = 5\n",
    "lr = 1e-4\n",
    "lr_decay_step = 10\n",
    "\n",
    "train_log_interval = 20\n",
    "\n",
    "# -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dramatic-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight = None, gamma = 2, reduction = 'mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim = -1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1-prob)**self.gamma) * log_prob, \n",
    "            target_tensor,\n",
    "            weight = self.weight,\n",
    "            reduction = self.reduction\n",
    "        )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integral-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Loss(nn.Module):\n",
    "    '''Calculate F1 score. Can work with gpu tensors\n",
    "    \n",
    "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        `ndim` == 1. epsilon <= val <= 1\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
    "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n",
    "    '''\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred, y_true,):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, 2).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civil-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Focal_F1(nn.Module):\n",
    "    def __init__(self, weight = None, gamma = 2, reduction = 'mean', epsilon=1e-7):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "#         def __init__(self, epsilon=1e-7):\n",
    "#         super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "    # def forward(self, input_tensor, target_tensor):\n",
    "        \n",
    "    def forward(self, input_tensor, target_tensor,):\n",
    "        assert input_tensor.ndim == 2\n",
    "        assert target_tensor.ndim == 1\n",
    "        target_tensor = F.one_hot(target_tensor, 2).to(torch.float32)\n",
    "        input_tensor = F.softmax(input_tensor, dim=1)\n",
    "        \n",
    "        tp = (target_tensor * input_tensor).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - target_tensor) * (1 - input_tensor)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - target_tensor) * input_tensor).sum(dim=0).to(torch.float32)\n",
    "        fn = (target_tensor * (1 - input_tensor)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        # return 1 - f1.mean()\n",
    "        log_prob = F.log_softmax(input_tensor, dim = -1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        \n",
    "        return F.nll_loss(\n",
    "            ((1-prob)**self.gamma) * log_prob, \n",
    "            target_tensor,\n",
    "            weight = self.weight,\n",
    "            reduction = self.reduction\n",
    "        ) + 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "korean-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sound-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model(model_name,pretrained = True)\n",
    "# # model\n",
    "# # last_num  = model.classifier.in_features\n",
    "# # model.classifier = nn.Linear(last_num,num_classes,bias=True)\n",
    "# model.reset_classifier(num_classes)\n",
    "# model.to(device)\n",
    "\n",
    "# optimizer = AdamP(model.parameters(), lr = lr, weight_decay = 5e-4)\n",
    "\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max = 2, eta_min = 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "physical-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration\n",
    "data_dir = '/opt/ml/input/data/train'\n",
    "img_dir = f'{data_dir}/images'\n",
    "df_path = f'{data_dir}/train.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# 한 디렉토리 안에 여러 확장자가 들어있는 경우에 맞게 수정\n",
    "def get_ext(img_dir,img_id):\n",
    "    filename = glob(os.path.join(img_dir,img_id)+'/*.*')\n",
    "#     print(filename)\n",
    "    ext = list(map(lambda x : os.path.splitext(x)[-1].lower(), filename))\n",
    "    return ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuing-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# def get_transforms(need = ('train','val'), img_size = (512,384), mean = (0.560, .524,.501), std = (.233,.243,.247)):\n",
    "def get_transforms(need = ('train','val'), img_size = (300,300), mean = (0.560, .524,.501), std = (.233,.243,.247)):\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            CenterCrop(500,300, p = 1.),\n",
    "            HorizontalFlip(p = 0.5),\n",
    "            RandomBrightnessContrast(brightness_limit = (-0.1,0.1), contrast_limit = (-0.1,0.1), p = 0.5),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value = 255., p = 1.),\n",
    "            ToTensorV2(p = 1.),\n",
    "        ], p = 1.)\n",
    "        \n",
    "    if 'val' in need :\n",
    "        transformations['val'] = Compose([\n",
    "            CenterCrop(500,300, p = 1.),\n",
    "            Normalize(mean = mean, std=std, max_pixel_value = 255. , p = 1.),\n",
    "            ToTensorV2(p = 1.),\n",
    "        ], p = 1.)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sticky-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels:\n",
    "    mask = 0\n",
    "    incorrect = 1\n",
    "    normal = 2\n",
    "    \n",
    "class GenderLabels:\n",
    "    male = 0\n",
    "    female = 1\n",
    "    \n",
    "class AgeGroup:\n",
    "    map_label = lambda x : 0 if int(x) < 30 else 1 if int(x) < 58 else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aquatic-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3*2\n",
    "#     num_classes = 3*2*3\n",
    "    \n",
    "    _file_names = {\n",
    "        'mask1' : MaskLabels.mask,\n",
    "        'mask2' : MaskLabels.mask,\n",
    "        'mask3' : MaskLabels.mask,\n",
    "        'mask4' : MaskLabels.mask,\n",
    "        'mask5' : MaskLabels.mask,\n",
    "        'incorrect_mask' : MaskLabels.incorrect,\n",
    "        'normal' : MaskLabels.normal\n",
    "    }\n",
    "    \n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels =[]\n",
    "    age_labels = []\n",
    "    multi_labels = []\n",
    "    def __init__(self, img_dir, transform = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.setup()\n",
    "        \n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def setup(self):\n",
    "        profiles = glob(self.img_dir+\"/*\")\n",
    "        for profile in profiles:\n",
    "            for file_name, label in zip(list(map(lambda x: x[0]+x[1], zip(self._file_names.keys(), get_ext(\"\",profile)))),self._file_names.values()):\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)\n",
    "                if os.path.exists(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    id, gender, race, age = profile.split('_')\n",
    "                    gender_label = getattr(GenderLabels,gender)\n",
    "                    age_label = AgeGroup.map_label(age)\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "                    self.multi_labels.append(gender_label * 3 + age_label)\n",
    "    def __getitem__(self, index, item = None):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "#         multi_class_label = gender_label * 3 + age_label\n",
    "        multi_class_label = self.multi_labels[index]\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loved-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.560, .524,.501)\n",
    "std = (.233,.243,.247)\n",
    "transform = get_transforms(mean = mean, std = std)\n",
    "    \n",
    "dataset = MaskBaseDataset(img_dir = img_dir)\n",
    "\n",
    "# n_val = int(len(dataset) * val_split)\n",
    "# n_train = len(dataset) - n_val\n",
    "# train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# train_dataset.dataset.set_transform(transform['train'])\n",
    "# val_dataset.dataset.set_transform(transform['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "academic-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhwan17\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">solar-lion-18</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hwan17/uncategorized\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2399jwhs\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2399jwhs</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/Day_9/wandb/run-20210408_054529-2399jwhs</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](20/237)||training loss 0.8015 || training accuracy 62.81% || lr [0.0001]\n",
      "Epoch[0/5](40/237)||training loss 0.3036 || training accuracy 79.06% || lr [0.0001]\n",
      "Epoch[0/5](60/237)||training loss 0.1584 || training accuracy 83.36% || lr [0.0001]\n",
      "Epoch[0/5](80/237)||training loss 0.1628 || training accuracy 83.83% || lr [0.0001]\n",
      "Epoch[0/5](100/237)||training loss 0.1078 || training accuracy 87.11% || lr [0.0001]\n",
      "Epoch[0/5](120/237)||training loss 0.1063 || training accuracy 87.27% || lr [0.0001]\n",
      "Epoch[0/5](140/237)||training loss 0.1013 || training accuracy 86.95% || lr [0.0001]\n",
      "Epoch[0/5](160/237)||training loss 0.08308 || training accuracy 89.77% || lr [0.0001]\n",
      "Epoch[0/5](180/237)||training loss 0.08073 || training accuracy 88.75% || lr [0.0001]\n",
      "Epoch[0/5](200/237)||training loss 0.06814 || training accuracy 91.25% || lr [0.0001]\n",
      "Epoch[0/5](220/237)||training loss 0.05989 || training accuracy 91.88% || lr [0.0001]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 80.50%, loss : 0.18 ||best acc : 80.50%, best loss: 0.18\n",
      "Epoch[1/5](20/237)||training loss 0.04023 || training accuracy 95.78% || lr [5e-05]\n",
      "Epoch[1/5](40/237)||training loss 0.03211 || training accuracy 96.64% || lr [5e-05]\n",
      "Epoch[1/5](60/237)||training loss 0.02219 || training accuracy 97.73% || lr [5e-05]\n",
      "Epoch[1/5](80/237)||training loss 0.02777 || training accuracy 97.50% || lr [5e-05]\n",
      "Epoch[1/5](100/237)||training loss 0.02237 || training accuracy 97.34% || lr [5e-05]\n",
      "Epoch[1/5](120/237)||training loss 0.02498 || training accuracy 97.81% || lr [5e-05]\n",
      "Epoch[1/5](140/237)||training loss 0.01707 || training accuracy 98.36% || lr [5e-05]\n",
      "Epoch[1/5](160/237)||training loss 0.01565 || training accuracy 97.89% || lr [5e-05]\n",
      "Epoch[1/5](180/237)||training loss 0.01566 || training accuracy 98.05% || lr [5e-05]\n",
      "Epoch[1/5](200/237)||training loss 0.01254 || training accuracy 98.98% || lr [5e-05]\n",
      "Epoch[1/5](220/237)||training loss 0.01472 || training accuracy 98.05% || lr [5e-05]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.67%, loss : 0.25 ||best acc : 82.67%, best loss: 0.18\n",
      "Epoch[2/5](20/237)||training loss 0.006041 || training accuracy 99.53% || lr [0.0]\n",
      "Epoch[2/5](40/237)||training loss 0.009666 || training accuracy 99.22% || lr [0.0]\n",
      "Epoch[2/5](60/237)||training loss 0.007026 || training accuracy 99.53% || lr [0.0]\n",
      "Epoch[2/5](80/237)||training loss 0.005404 || training accuracy 99.69% || lr [0.0]\n",
      "Epoch[2/5](100/237)||training loss 0.006037 || training accuracy 99.61% || lr [0.0]\n",
      "Epoch[2/5](120/237)||training loss 0.005085 || training accuracy 99.92% || lr [0.0]\n",
      "Epoch[2/5](140/237)||training loss 0.007316 || training accuracy 99.45% || lr [0.0]\n",
      "Epoch[2/5](160/237)||training loss 0.005524 || training accuracy 99.84% || lr [0.0]\n",
      "Epoch[2/5](180/237)||training loss 0.005657 || training accuracy 99.69% || lr [0.0]\n",
      "Epoch[2/5](200/237)||training loss 0.008156 || training accuracy 99.38% || lr [0.0]\n",
      "Epoch[2/5](220/237)||training loss 0.008266 || training accuracy 99.38% || lr [0.0]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.99%, loss : 0.24 ||best acc : 82.99%, best loss: 0.18\n",
      "Epoch[3/5](20/237)||training loss 0.007668 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](40/237)||training loss 0.005132 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](60/237)||training loss 0.005663 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](80/237)||training loss 0.005543 || training accuracy 99.61% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](100/237)||training loss 0.003633 || training accuracy 99.69% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](120/237)||training loss 0.003152 || training accuracy 99.77% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](140/237)||training loss 0.004742 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](160/237)||training loss 0.01043 || training accuracy 98.98% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](180/237)||training loss 0.006429 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](200/237)||training loss 0.005029 || training accuracy 99.61% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](220/237)||training loss 0.007347 || training accuracy 99.06% || lr [4.9999999999999996e-05]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 84.42%, loss :  0.3 ||best acc : 84.42%, best loss: 0.18\n",
      "Epoch[4/5](20/237)||training loss 0.006284 || training accuracy 99.30% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](40/237)||training loss 0.01545 || training accuracy 98.59% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](60/237)||training loss 0.0164 || training accuracy 98.12% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](80/237)||training loss 0.02055 || training accuracy 97.66% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](100/237)||training loss 0.023 || training accuracy 96.95% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](120/237)||training loss 0.01746 || training accuracy 98.20% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](140/237)||training loss 0.01707 || training accuracy 98.20% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](160/237)||training loss 0.01765 || training accuracy 97.97% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](180/237)||training loss 0.01667 || training accuracy 98.20% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](200/237)||training loss 0.01704 || training accuracy 98.52% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](220/237)||training loss 0.02349 || training accuracy 97.27% || lr [0.00010000000000000002]\n",
      "Calculating validation results\n",
      "[Val] acc : 77.57%, loss : 0.38 ||best acc : 84.42%, best loss: 0.18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2399jwhs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13665<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_054529-2399jwhs/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_054529-2399jwhs/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>0.02349</td></tr><tr><td>Train_acc</td><td>0.97266</td></tr><tr><td>_runtime</td><td>1129</td></tr><tr><td>_timestamp</td><td>1617861858</td></tr><tr><td>_step</td><td>59</td></tr><tr><td>Valid_loss</td><td>0.37625</td></tr><tr><td>Valid_acc</td><td>0.77566</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>█▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train_acc</td><td>▁▄▅▆▆▆▆▆▇▇█████████████████████████▇███▇</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Valid_loss</td><td>▁▄▃▆█</td></tr><tr><td>Valid_acc</td><td>▄▆▇█▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">solar-lion-18</strong>: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2399jwhs\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2399jwhs</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2399jwhs). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-frost-19</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hwan17/uncategorized\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2r1clvvd\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2r1clvvd</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/Day_9/wandb/run-20210408_060419-2r1clvvd</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](20/237)||training loss 0.8465 || training accuracy 60.00% || lr [0.0001]\n",
      "Epoch[0/5](40/237)||training loss 0.3368 || training accuracy 79.30% || lr [0.0001]\n",
      "Epoch[0/5](60/237)||training loss 0.1947 || training accuracy 82.27% || lr [0.0001]\n",
      "Epoch[0/5](80/237)||training loss 0.1438 || training accuracy 83.52% || lr [0.0001]\n",
      "Epoch[0/5](100/237)||training loss 0.141 || training accuracy 83.36% || lr [0.0001]\n",
      "Epoch[0/5](120/237)||training loss 0.1095 || training accuracy 87.81% || lr [0.0001]\n",
      "Epoch[0/5](140/237)||training loss 0.104 || training accuracy 87.66% || lr [0.0001]\n",
      "Epoch[0/5](160/237)||training loss 0.08892 || training accuracy 90.78% || lr [0.0001]\n",
      "Epoch[0/5](180/237)||training loss 0.07328 || training accuracy 91.17% || lr [0.0001]\n",
      "Epoch[0/5](200/237)||training loss 0.06273 || training accuracy 91.72% || lr [0.0001]\n",
      "Epoch[0/5](220/237)||training loss 0.05354 || training accuracy 92.97% || lr [0.0001]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 81.50%, loss : 0.18 ||best acc : 81.50%, best loss: 0.18\n",
      "Epoch[1/5](20/237)||training loss 0.03247 || training accuracy 96.09% || lr [5e-05]\n",
      "Epoch[1/5](40/237)||training loss 0.0339 || training accuracy 96.48% || lr [5e-05]\n",
      "Epoch[1/5](60/237)||training loss 0.02928 || training accuracy 96.56% || lr [5e-05]\n",
      "Epoch[1/5](80/237)||training loss 0.01987 || training accuracy 97.73% || lr [5e-05]\n",
      "Epoch[1/5](100/237)||training loss 0.02475 || training accuracy 97.42% || lr [5e-05]\n",
      "Epoch[1/5](120/237)||training loss 0.02199 || training accuracy 97.50% || lr [5e-05]\n",
      "Epoch[1/5](140/237)||training loss 0.01523 || training accuracy 98.67% || lr [5e-05]\n",
      "Epoch[1/5](160/237)||training loss 0.016 || training accuracy 98.52% || lr [5e-05]\n",
      "Epoch[1/5](180/237)||training loss 0.01261 || training accuracy 98.91% || lr [5e-05]\n",
      "Epoch[1/5](200/237)||training loss 0.01115 || training accuracy 99.22% || lr [5e-05]\n",
      "Epoch[1/5](220/237)||training loss 0.009075 || training accuracy 99.06% || lr [5e-05]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 83.59%, loss : 0.22 ||best acc : 83.59%, best loss: 0.18\n",
      "Epoch[2/5](20/237)||training loss 0.007973 || training accuracy 99.30% || lr [0.0]\n",
      "Epoch[2/5](40/237)||training loss 0.01009 || training accuracy 99.14% || lr [0.0]\n",
      "Epoch[2/5](60/237)||training loss 0.008772 || training accuracy 99.14% || lr [0.0]\n",
      "Epoch[2/5](80/237)||training loss 0.01267 || training accuracy 98.52% || lr [0.0]\n",
      "Epoch[2/5](100/237)||training loss 0.007807 || training accuracy 99.22% || lr [0.0]\n",
      "Epoch[2/5](120/237)||training loss 0.009891 || training accuracy 98.98% || lr [0.0]\n",
      "Epoch[2/5](140/237)||training loss 0.009904 || training accuracy 99.06% || lr [0.0]\n",
      "Epoch[2/5](160/237)||training loss 0.01101 || training accuracy 98.91% || lr [0.0]\n",
      "Epoch[2/5](180/237)||training loss 0.01223 || training accuracy 98.44% || lr [0.0]\n",
      "Epoch[2/5](200/237)||training loss 0.01423 || training accuracy 98.20% || lr [0.0]\n",
      "Epoch[2/5](220/237)||training loss 0.0074 || training accuracy 99.45% || lr [0.0]\n",
      "Calculating validation results\n",
      "[Val] acc : 83.30%, loss : 0.23 ||best acc : 83.59%, best loss: 0.18\n",
      "Epoch[3/5](20/237)||training loss 0.01479 || training accuracy 98.52% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](40/237)||training loss 0.01086 || training accuracy 98.75% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](60/237)||training loss 0.00921 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](80/237)||training loss 0.006508 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](100/237)||training loss 0.009907 || training accuracy 98.59% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](120/237)||training loss 0.006218 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](140/237)||training loss 0.006096 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](160/237)||training loss 0.007215 || training accuracy 99.38% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](180/237)||training loss 0.003897 || training accuracy 99.69% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](200/237)||training loss 0.003423 || training accuracy 99.92% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](220/237)||training loss 0.005365 || training accuracy 99.69% || lr [4.9999999999999996e-05]\n",
      "Calculating validation results\n",
      "[Val] acc : 83.01%, loss : 0.28 ||best acc : 83.59%, best loss: 0.18\n",
      "Epoch[4/5](20/237)||training loss 0.01229 || training accuracy 98.59% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](40/237)||training loss 0.02541 || training accuracy 97.34% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](60/237)||training loss 0.02304 || training accuracy 97.11% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](80/237)||training loss 0.02474 || training accuracy 97.58% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](100/237)||training loss 0.01311 || training accuracy 98.36% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](120/237)||training loss 0.02251 || training accuracy 97.27% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](140/237)||training loss 0.02533 || training accuracy 97.42% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](160/237)||training loss 0.01246 || training accuracy 98.75% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](180/237)||training loss 0.02896 || training accuracy 96.80% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](200/237)||training loss 0.02693 || training accuracy 96.80% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](220/237)||training loss 0.01299 || training accuracy 98.44% || lr [0.00010000000000000002]\n",
      "Calculating validation results\n",
      "[Val] acc : 80.92%, loss : 0.25 ||best acc : 83.59%, best loss: 0.18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2r1clvvd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15489<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_060419-2r1clvvd/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_060419-2r1clvvd/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>0.01299</td></tr><tr><td>Train_acc</td><td>0.98438</td></tr><tr><td>_runtime</td><td>1129</td></tr><tr><td>_timestamp</td><td>1617862991</td></tr><tr><td>_step</td><td>59</td></tr><tr><td>Valid_loss</td><td>0.24959</td></tr><tr><td>Valid_acc</td><td>0.80921</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇███████████████████████████▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Valid_loss</td><td>▁▄▄█▆</td></tr><tr><td>Valid_acc</td><td>▃█▇▆▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">light-frost-19</strong>: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2r1clvvd\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2r1clvvd</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2r1clvvd). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">pretty-feather-20</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hwan17/uncategorized\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/1c66nl5o\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/1c66nl5o</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/Day_9/wandb/run-20210408_062312-1c66nl5o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](20/237)||training loss 0.8299 || training accuracy 63.44% || lr [0.0001]\n",
      "Epoch[0/5](40/237)||training loss 0.3106 || training accuracy 79.45% || lr [0.0001]\n",
      "Epoch[0/5](60/237)||training loss 0.193 || training accuracy 83.05% || lr [0.0001]\n",
      "Epoch[0/5](80/237)||training loss 0.1384 || training accuracy 86.95% || lr [0.0001]\n",
      "Epoch[0/5](100/237)||training loss 0.1273 || training accuracy 86.33% || lr [0.0001]\n",
      "Epoch[0/5](120/237)||training loss 0.1131 || training accuracy 86.56% || lr [0.0001]\n",
      "Epoch[0/5](140/237)||training loss 0.09049 || training accuracy 88.75% || lr [0.0001]\n",
      "Epoch[0/5](160/237)||training loss 0.07989 || training accuracy 91.02% || lr [0.0001]\n",
      "Epoch[0/5](180/237)||training loss 0.07481 || training accuracy 91.80% || lr [0.0001]\n",
      "Epoch[0/5](200/237)||training loss 0.06434 || training accuracy 92.19% || lr [0.0001]\n",
      "Epoch[0/5](220/237)||training loss 0.05754 || training accuracy 92.73% || lr [0.0001]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.01%, loss : 0.16 ||best acc : 82.01%, best loss: 0.16\n",
      "Epoch[1/5](20/237)||training loss 0.04376 || training accuracy 95.08% || lr [5e-05]\n",
      "Epoch[1/5](40/237)||training loss 0.03502 || training accuracy 95.55% || lr [5e-05]\n",
      "Epoch[1/5](60/237)||training loss 0.02962 || training accuracy 96.33% || lr [5e-05]\n",
      "Epoch[1/5](80/237)||training loss 0.02222 || training accuracy 97.58% || lr [5e-05]\n",
      "Epoch[1/5](100/237)||training loss 0.02283 || training accuracy 97.42% || lr [5e-05]\n",
      "Epoch[1/5](120/237)||training loss 0.01604 || training accuracy 98.36% || lr [5e-05]\n",
      "Epoch[1/5](140/237)||training loss 0.01683 || training accuracy 98.28% || lr [5e-05]\n",
      "Epoch[1/5](160/237)||training loss 0.01399 || training accuracy 98.52% || lr [5e-05]\n",
      "Epoch[1/5](180/237)||training loss 0.01258 || training accuracy 98.59% || lr [5e-05]\n",
      "Epoch[1/5](200/237)||training loss 0.009247 || training accuracy 99.30% || lr [5e-05]\n",
      "Epoch[1/5](220/237)||training loss 0.008814 || training accuracy 99.30% || lr [5e-05]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 83.22%, loss : 0.21 ||best acc : 83.22%, best loss: 0.16\n",
      "Epoch[2/5](20/237)||training loss 0.006682 || training accuracy 99.61% || lr [0.0]\n",
      "Epoch[2/5](40/237)||training loss 0.006009 || training accuracy 99.69% || lr [0.0]\n",
      "Epoch[2/5](60/237)||training loss 0.00617 || training accuracy 99.61% || lr [0.0]\n",
      "Epoch[2/5](80/237)||training loss 0.007679 || training accuracy 99.38% || lr [0.0]\n",
      "Epoch[2/5](100/237)||training loss 0.007639 || training accuracy 99.14% || lr [0.0]\n",
      "Epoch[2/5](120/237)||training loss 0.007238 || training accuracy 99.61% || lr [0.0]\n",
      "Epoch[2/5](140/237)||training loss 0.005084 || training accuracy 99.69% || lr [0.0]\n",
      "Epoch[2/5](160/237)||training loss 0.007239 || training accuracy 99.45% || lr [0.0]\n",
      "Epoch[2/5](180/237)||training loss 0.007504 || training accuracy 99.22% || lr [0.0]\n",
      "Epoch[2/5](200/237)||training loss 0.005447 || training accuracy 99.77% || lr [0.0]\n",
      "Epoch[2/5](220/237)||training loss 0.006814 || training accuracy 99.38% || lr [0.0]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 83.70%, loss : 0.21 ||best acc : 83.70%, best loss: 0.16\n",
      "Epoch[3/5](20/237)||training loss 0.006508 || training accuracy 99.30% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](40/237)||training loss 0.008652 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](60/237)||training loss 0.006619 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](80/237)||training loss 0.007054 || training accuracy 99.30% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](100/237)||training loss 0.005078 || training accuracy 99.61% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](120/237)||training loss 0.003373 || training accuracy 99.69% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](140/237)||training loss 0.00529 || training accuracy 99.61% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](160/237)||training loss 0.00666 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](180/237)||training loss 0.004852 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](200/237)||training loss 0.005897 || training accuracy 99.38% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](220/237)||training loss 0.009142 || training accuracy 98.98% || lr [4.9999999999999996e-05]\n",
      "Calculating validation results\n",
      "[Val] acc : 83.62%, loss : 0.26 ||best acc : 83.70%, best loss: 0.16\n",
      "Epoch[4/5](20/237)||training loss 0.006482 || training accuracy 99.30% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](40/237)||training loss 0.009663 || training accuracy 98.98% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](60/237)||training loss 0.006455 || training accuracy 99.22% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](80/237)||training loss 0.01086 || training accuracy 99.30% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](100/237)||training loss 0.01735 || training accuracy 98.36% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](120/237)||training loss 0.02054 || training accuracy 96.95% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](140/237)||training loss 0.02172 || training accuracy 97.66% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](160/237)||training loss 0.0343 || training accuracy 96.33% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](180/237)||training loss 0.02461 || training accuracy 97.19% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](200/237)||training loss 0.02534 || training accuracy 96.95% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](220/237)||training loss 0.01763 || training accuracy 97.97% || lr [0.00010000000000000002]\n",
      "Calculating validation results\n",
      "[Val] acc : 82.01%, loss : 0.26 ||best acc : 83.70%, best loss: 0.16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1c66nl5o) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17294<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_062312-1c66nl5o/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_062312-1c66nl5o/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>0.01763</td></tr><tr><td>Train_acc</td><td>0.97969</td></tr><tr><td>_runtime</td><td>1150</td></tr><tr><td>_timestamp</td><td>1617864145</td></tr><tr><td>_step</td><td>59</td></tr><tr><td>Valid_loss</td><td>0.26074</td></tr><tr><td>Valid_acc</td><td>0.82006</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train_acc</td><td>▁▄▅▅▅▆▆▇▇▇▇█████████████████████████▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Valid_loss</td><td>▁▅▄██</td></tr><tr><td>Valid_acc</td><td>▁▆██▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">pretty-feather-20</strong>: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/1c66nl5o\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/1c66nl5o</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1c66nl5o). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wise-spaceship-21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hwan17/uncategorized\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2fblw9u0\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2fblw9u0</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/Day_9/wandb/run-20210408_064225-2fblw9u0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](20/237)||training loss 0.8081 || training accuracy 63.44% || lr [0.0001]\n",
      "Epoch[0/5](40/237)||training loss 0.3223 || training accuracy 79.30% || lr [0.0001]\n",
      "Epoch[0/5](60/237)||training loss 0.1855 || training accuracy 83.05% || lr [0.0001]\n",
      "Epoch[0/5](80/237)||training loss 0.1551 || training accuracy 84.69% || lr [0.0001]\n",
      "Epoch[0/5](100/237)||training loss 0.1355 || training accuracy 84.61% || lr [0.0001]\n",
      "Epoch[0/5](120/237)||training loss 0.1084 || training accuracy 86.33% || lr [0.0001]\n",
      "Epoch[0/5](140/237)||training loss 0.08914 || training accuracy 89.06% || lr [0.0001]\n",
      "Epoch[0/5](160/237)||training loss 0.08062 || training accuracy 89.61% || lr [0.0001]\n",
      "Epoch[0/5](180/237)||training loss 0.07808 || training accuracy 90.62% || lr [0.0001]\n",
      "Epoch[0/5](200/237)||training loss 0.07743 || training accuracy 90.47% || lr [0.0001]\n",
      "Epoch[0/5](220/237)||training loss 0.07902 || training accuracy 90.47% || lr [0.0001]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.59%, loss : 0.17 ||best acc : 82.59%, best loss: 0.17\n",
      "Epoch[1/5](20/237)||training loss 0.04336 || training accuracy 94.30% || lr [5e-05]\n",
      "Epoch[1/5](40/237)||training loss 0.03599 || training accuracy 95.62% || lr [5e-05]\n",
      "Epoch[1/5](60/237)||training loss 0.02935 || training accuracy 96.72% || lr [5e-05]\n",
      "Epoch[1/5](80/237)||training loss 0.02298 || training accuracy 97.19% || lr [5e-05]\n",
      "Epoch[1/5](100/237)||training loss 0.02202 || training accuracy 97.50% || lr [5e-05]\n",
      "Epoch[1/5](120/237)||training loss 0.01906 || training accuracy 98.12% || lr [5e-05]\n",
      "Epoch[1/5](140/237)||training loss 0.02191 || training accuracy 97.34% || lr [5e-05]\n",
      "Epoch[1/5](160/237)||training loss 0.01622 || training accuracy 98.12% || lr [5e-05]\n",
      "Epoch[1/5](180/237)||training loss 0.01396 || training accuracy 98.75% || lr [5e-05]\n",
      "Epoch[1/5](200/237)||training loss 0.01288 || training accuracy 98.83% || lr [5e-05]\n",
      "Epoch[1/5](220/237)||training loss 0.01391 || training accuracy 98.28% || lr [5e-05]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 83.96%, loss : 0.27 ||best acc : 83.96%, best loss: 0.17\n",
      "Epoch[2/5](20/237)||training loss 0.006529 || training accuracy 99.38% || lr [0.0]\n",
      "Epoch[2/5](40/237)||training loss 0.007216 || training accuracy 99.38% || lr [0.0]\n",
      "Epoch[2/5](60/237)||training loss 0.006109 || training accuracy 99.45% || lr [0.0]\n",
      "Epoch[2/5](80/237)||training loss 0.01195 || training accuracy 98.67% || lr [0.0]\n",
      "Epoch[2/5](100/237)||training loss 0.009968 || training accuracy 98.98% || lr [0.0]\n",
      "Epoch[2/5](120/237)||training loss 0.006405 || training accuracy 99.38% || lr [0.0]\n",
      "Epoch[2/5](140/237)||training loss 0.008687 || training accuracy 99.30% || lr [0.0]\n",
      "Epoch[2/5](160/237)||training loss 0.00782 || training accuracy 99.53% || lr [0.0]\n",
      "Epoch[2/5](180/237)||training loss 0.009155 || training accuracy 99.38% || lr [0.0]\n",
      "Epoch[2/5](200/237)||training loss 0.01312 || training accuracy 98.75% || lr [0.0]\n",
      "Epoch[2/5](220/237)||training loss 0.00897 || training accuracy 98.91% || lr [0.0]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 84.26%, loss : 0.24 ||best acc : 84.26%, best loss: 0.17\n",
      "Epoch[3/5](20/237)||training loss 0.007086 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](40/237)||training loss 0.007457 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](60/237)||training loss 0.004618 || training accuracy 99.45% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](80/237)||training loss 0.008403 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](100/237)||training loss 0.004787 || training accuracy 99.61% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](120/237)||training loss 0.00598 || training accuracy 99.38% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](140/237)||training loss 0.007956 || training accuracy 98.91% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](160/237)||training loss 0.004115 || training accuracy 99.61% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](180/237)||training loss 0.004905 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](200/237)||training loss 0.005594 || training accuracy 99.30% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](220/237)||training loss 0.005073 || training accuracy 99.69% || lr [4.9999999999999996e-05]\n",
      "Calculating validation results\n",
      "[Val] acc : 82.88%, loss : 0.28 ||best acc : 84.26%, best loss: 0.17\n",
      "Epoch[4/5](20/237)||training loss 0.007754 || training accuracy 99.45% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](40/237)||training loss 0.008079 || training accuracy 99.22% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](60/237)||training loss 0.01804 || training accuracy 98.28% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](80/237)||training loss 0.01668 || training accuracy 98.05% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](100/237)||training loss 0.02298 || training accuracy 97.27% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](120/237)||training loss 0.03099 || training accuracy 96.88% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](140/237)||training loss 0.0321 || training accuracy 96.41% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](160/237)||training loss 0.02662 || training accuracy 96.48% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](180/237)||training loss 0.02837 || training accuracy 96.95% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](200/237)||training loss 0.02256 || training accuracy 97.66% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](220/237)||training loss 0.02145 || training accuracy 97.27% || lr [0.00010000000000000002]\n",
      "Calculating validation results\n",
      "[Val] acc : 78.41%, loss :  0.3 ||best acc : 84.26%, best loss: 0.17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2fblw9u0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19126<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_064225-2fblw9u0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/code/Day_9/wandb/run-20210408_064225-2fblw9u0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>0.02145</td></tr><tr><td>Train_acc</td><td>0.97266</td></tr><tr><td>_runtime</td><td>1138</td></tr><tr><td>_timestamp</td><td>1617865287</td></tr><tr><td>_step</td><td>59</td></tr><tr><td>Valid_loss</td><td>0.30389</td></tr><tr><td>Valid_acc</td><td>0.78407</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train_acc</td><td>▁▄▅▅▅▆▆▆▇▇▇█████████████████████████▇▇▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Valid_loss</td><td>▁▆▄▇█</td></tr><tr><td>Valid_acc</td><td>▆██▆▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wise-spaceship-21</strong>: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2fblw9u0\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2fblw9u0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2fblw9u0). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">solar-snowflake-22</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hwan17/uncategorized\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hwan17/uncategorized/runs/2ojbbndf\" target=\"_blank\">https://wandb.ai/hwan17/uncategorized/runs/2ojbbndf</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/Day_9/wandb/run-20210408_070128-2ojbbndf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](20/237)||training loss 0.8522 || training accuracy 61.48% || lr [0.0001]\n",
      "Epoch[0/5](40/237)||training loss 0.337 || training accuracy 79.53% || lr [0.0001]\n",
      "Epoch[0/5](60/237)||training loss 0.1816 || training accuracy 83.75% || lr [0.0001]\n",
      "Epoch[0/5](80/237)||training loss 0.1345 || training accuracy 86.41% || lr [0.0001]\n",
      "Epoch[0/5](100/237)||training loss 0.1268 || training accuracy 86.72% || lr [0.0001]\n",
      "Epoch[0/5](120/237)||training loss 0.1085 || training accuracy 88.28% || lr [0.0001]\n",
      "Epoch[0/5](140/237)||training loss 0.1021 || training accuracy 88.28% || lr [0.0001]\n",
      "Epoch[0/5](160/237)||training loss 0.07166 || training accuracy 90.78% || lr [0.0001]\n",
      "Epoch[0/5](180/237)||training loss 0.07461 || training accuracy 91.09% || lr [0.0001]\n",
      "Epoch[0/5](200/237)||training loss 0.0718 || training accuracy 93.05% || lr [0.0001]\n",
      "Epoch[0/5](220/237)||training loss 0.05712 || training accuracy 92.66% || lr [0.0001]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 83.43%, loss : 0.17 ||best acc : 83.43%, best loss: 0.17\n",
      "Epoch[1/5](20/237)||training loss 0.03353 || training accuracy 96.88% || lr [5e-05]\n",
      "Epoch[1/5](40/237)||training loss 0.02589 || training accuracy 97.03% || lr [5e-05]\n",
      "Epoch[1/5](60/237)||training loss 0.0228 || training accuracy 97.42% || lr [5e-05]\n",
      "Epoch[1/5](80/237)||training loss 0.01607 || training accuracy 98.83% || lr [5e-05]\n",
      "Epoch[1/5](100/237)||training loss 0.01913 || training accuracy 98.52% || lr [5e-05]\n",
      "Epoch[1/5](120/237)||training loss 0.01789 || training accuracy 98.05% || lr [5e-05]\n",
      "Epoch[1/5](140/237)||training loss 0.01444 || training accuracy 98.67% || lr [5e-05]\n",
      "Epoch[1/5](160/237)||training loss 0.01438 || training accuracy 98.44% || lr [5e-05]\n",
      "Epoch[1/5](180/237)||training loss 0.01005 || training accuracy 98.91% || lr [5e-05]\n",
      "Epoch[1/5](200/237)||training loss 0.01104 || training accuracy 98.44% || lr [5e-05]\n",
      "Epoch[1/5](220/237)||training loss 0.01336 || training accuracy 98.67% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc : 82.40%, loss : 0.25 ||best acc : 83.43%, best loss: 0.17\n",
      "Epoch[2/5](20/237)||training loss 0.00657 || training accuracy 99.45% || lr [0.0]\n",
      "Epoch[2/5](40/237)||training loss 0.005875 || training accuracy 99.53% || lr [0.0]\n",
      "Epoch[2/5](60/237)||training loss 0.005648 || training accuracy 99.53% || lr [0.0]\n",
      "Epoch[2/5](80/237)||training loss 0.008003 || training accuracy 99.06% || lr [0.0]\n",
      "Epoch[2/5](100/237)||training loss 0.008309 || training accuracy 99.30% || lr [0.0]\n",
      "Epoch[2/5](120/237)||training loss 0.005945 || training accuracy 99.45% || lr [0.0]\n",
      "Epoch[2/5](140/237)||training loss 0.00936 || training accuracy 99.14% || lr [0.0]\n",
      "Epoch[2/5](160/237)||training loss 0.005066 || training accuracy 99.77% || lr [0.0]\n",
      "Epoch[2/5](180/237)||training loss 0.005626 || training accuracy 99.69% || lr [0.0]\n",
      "Epoch[2/5](200/237)||training loss 0.006674 || training accuracy 99.69% || lr [0.0]\n",
      "Epoch[2/5](220/237)||training loss 0.006859 || training accuracy 99.61% || lr [0.0]\n",
      "Calculating validation results\n",
      "[Val] acc : 82.51%, loss : 0.26 ||best acc : 83.43%, best loss: 0.17\n",
      "Epoch[3/5](20/237)||training loss 0.008131 || training accuracy 99.14% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](40/237)||training loss 0.009566 || training accuracy 99.30% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](60/237)||training loss 0.009656 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](80/237)||training loss 0.008139 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](100/237)||training loss 0.005943 || training accuracy 99.53% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](120/237)||training loss 0.008545 || training accuracy 99.14% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](140/237)||training loss 0.008765 || training accuracy 99.06% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](160/237)||training loss 0.006162 || training accuracy 99.30% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](180/237)||training loss 0.007171 || training accuracy 99.22% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](200/237)||training loss 0.009298 || training accuracy 98.83% || lr [4.9999999999999996e-05]\n",
      "Epoch[3/5](220/237)||training loss 0.00609 || training accuracy 99.30% || lr [4.9999999999999996e-05]\n",
      "Calculating validation results\n",
      "[Val] acc : 81.58%, loss : 0.33 ||best acc : 83.43%, best loss: 0.17\n",
      "Epoch[4/5](20/237)||training loss 0.02231 || training accuracy 97.97% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](40/237)||training loss 0.01901 || training accuracy 97.58% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](60/237)||training loss 0.02378 || training accuracy 97.58% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](80/237)||training loss 0.02028 || training accuracy 97.81% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](100/237)||training loss 0.02111 || training accuracy 97.58% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](120/237)||training loss 0.01992 || training accuracy 97.66% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](140/237)||training loss 0.0222 || training accuracy 97.73% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](160/237)||training loss 0.01355 || training accuracy 98.28% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](180/237)||training loss 0.01322 || training accuracy 98.36% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](200/237)||training loss 0.008741 || training accuracy 99.30% || lr [0.00010000000000000002]\n",
      "Epoch[4/5](220/237)||training loss 0.01364 || training accuracy 98.52% || lr [0.00010000000000000002]\n",
      "Calculating validation results\n",
      "[Val] acc : 81.77%, loss : 0.31 ||best acc : 83.43%, best loss: 0.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits =5)\n",
    "\n",
    "# stk = StratifiedKFold(n_splits=num_epochs, shuffle=False)\n",
    "# for fold, x in enumerate(stk.split(dataset.image_paths, dataset.age_gender_labels),1):\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.image_paths, dataset.multi_labels),1):\n",
    "#     print(fold,x)\n",
    "    train_dataset = data.Subset(dataset, train_idx)\n",
    "    val_dataset = data.Subset(dataset,val_idx)\n",
    "    train_dataset.dataset.set_transform(transform['train'])\n",
    "    val_dataset.dataset.set_transform(transform['val'])\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    val_loader = data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = False\n",
    "    )\n",
    "    \n",
    "    model = timm.create_model(model_name,pretrained = True)\n",
    "# model\n",
    "    # last_num  = model.classifier.in_features\n",
    "    # model.classifier = nn.Linear(last_num,num_classes,bias=True)\n",
    "    model.reset_classifier(num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamP(model.parameters(), lr = lr, weight_decay = 5e-4)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max = 2, eta_min = 0.)\n",
    "    patience = 10\n",
    "    counter = 0\n",
    "\n",
    "    accumulation_steps = 2\n",
    "\n",
    "\n",
    "\n",
    "    os.makedirs(os.path.join(os.getcwd(),'results2', model_name), exist_ok = True)\n",
    "    wandb.init(config= {\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": num_epochs,\n",
    "            \"backbone\": 'efficientnet_b3_pruned'\n",
    "\n",
    "        })\n",
    "    counter =0 \n",
    "    best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(num_epochs):\n",
    "        #train loop\n",
    "        model.train()\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for idx, train_batch in enumerate(train_loader):\n",
    "            inputs, labels= train_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim = -1)\n",
    "            loss = criterion(outs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (idx+1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == labels).sum().item()\n",
    "            if (idx+1) % train_log_interval == 0:\n",
    "                train_loss = loss_value/ train_log_interval\n",
    "                train_acc = matches / batch_size/ train_log_interval\n",
    "                current_lr = scheduler.get_last_lr()\n",
    "                wandb.log({\n",
    "                        \"Train_loss\": train_loss,\n",
    "                        \"Train_acc\": train_acc\n",
    "                    })\n",
    "                print(\n",
    "                    f'Epoch[{epoch}/{num_epochs}]({idx+1}/{len(train_loader)})||'\n",
    "                    f'training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}'\n",
    "                )\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0\n",
    "        scheduler.step()\n",
    "\n",
    "        #val loop\n",
    "        with torch.no_grad():\n",
    "            print(\"Calculating validation results\")\n",
    "            model.eval()\n",
    "            val_loss_items = []\n",
    "            val_acc_items= []\n",
    "            for val_batch in val_loader:\n",
    "                inputs, labels = val_batch\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outs = model(inputs)\n",
    "                preds = torch.argmax(outs, dim = -1)\n",
    "\n",
    "                loss_item = criterion(outs, labels).item()\n",
    "                acc_item = (labels == preds).sum().item()\n",
    "                val_loss_items.append(loss_item)\n",
    "                val_acc_items.append(acc_item)\n",
    "\n",
    "            val_loss = np.sum(val_loss_items)/ len(val_loader)\n",
    "            val_acc  = np.sum(val_acc_items)/ len(val_dataset)\n",
    "            wandb.log({\n",
    "                    \"Valid_loss\": val_loss,\n",
    "                    \"Valid_acc\": val_acc\n",
    "                })\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "            if val_acc > best_val_acc:\n",
    "                print('New best model for val accuracy! saving the model..')\n",
    "                now = time.localtime()\n",
    "    # print(now.tm_hour+9)\n",
    "                torch.save(model.state_dict(), f'results2/{model_name}/{fold}fold_{epoch:03}_accuracy_{val_acc:4.2%}_{now.tm_hour+9}:{now.tm_min}_agegender.ckpt')\n",
    "                best_val_acc = val_acc\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "\n",
    "            if counter > patience:\n",
    "                print('Early stopping...')\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f'[Val] acc : {val_acc:4.2%}, loss : {val_loss:4.2} ||'\n",
    "                f'best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dominican-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/ogg;base64,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\" type=\"audio/ogg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bound-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "progressive-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name,pretrained = True)\n",
    "# last_num  = model.classifier.in_features\n",
    "# model.classifier = nn.Linear(last_num,3,bias=True)\n",
    "model.reset_classifier(3)\n",
    "model.to(device)\n",
    "optimizer = AdamP(model.parameters(), lr = lr, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "moved-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingLR(optimizer, T_max = 2, eta_min = 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "remarkable-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Configuration\n",
    "# data_dir = '/opt/ml/input/data/train'\n",
    "# img_dir = f'{data_dir}/images'\n",
    "# df_path = f'{data_dir}/train.csv'\n",
    "# df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "parental-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 한 디렉토리 안에 여러 확장자가 들어있는 경우에 맞게 수정\n",
    "# def get_ext(img_dir,img_id):\n",
    "#     filename = glob(os.path.join(img_dir,img_id)+'/*.*')\n",
    "#     ext = list(map(lambda x : os.path.splitext(x)[-1].lower(), filename))\n",
    "#     return ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "valid-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# def get_transforms(need = ('train','val'), img_size = (512,384), mean = (0.560, .524,.501), std = (.233,.243,.247)):\n",
    "def get_transforms(need = ('train','val'), img_size = (300,300), mean = (0.560, .524,.501), std = (.233,.243,.247)):\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            CenterCrop(500,300, p = 1.),\n",
    "            HorizontalFlip(p = 0.5),\n",
    "            RandomBrightnessContrast(brightness_limit = (-0.1,0.1), contrast_limit = (-0.1,0.1), p = 0.5),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value = 255., p = 1.),\n",
    "            ToTensorV2(p = 1.),\n",
    "        ], p = 1.)\n",
    "        \n",
    "    if 'val' in need :\n",
    "        transformations['val'] = Compose([\n",
    "            CenterCrop(500,300, p = 1.),\n",
    "            Normalize(mean = mean, std=std, max_pixel_value = 255. , p = 1.),\n",
    "            ToTensorV2(p = 1.),\n",
    "        ], p = 1.)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "institutional-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3*2*3\n",
    "\n",
    "    class MaskLabels:\n",
    "        mask = 0\n",
    "        incorrect = 1\n",
    "        normal = 2\n",
    "\n",
    "    class GenderLabels:\n",
    "        male = 0\n",
    "        female = 1\n",
    "\n",
    "    class AgeGroup:\n",
    "        map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 58 else 2\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\":MaskLabels.mask,\n",
    "        \"mask2\":MaskLabels.mask,\n",
    "        \"mask3\":MaskLabels.mask,\n",
    "        \"mask4\":MaskLabels.mask,\n",
    "        \"mask1\":MaskLabels.mask,\n",
    "        \"incorrect_mask\":MaskLabels.incorrect,\n",
    "        \"normal\": MaskLabels.normal\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "    # 위와 같이 저장되는 값이 init에 저장될 때와 안될 때의 차이?\n",
    "\n",
    "    def __init__(self, data_dir, mean = (.548, .504, .479), std = (.237, .247, .246), val_ratio = 0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "        self.transform = None\n",
    "        self.setup()\n",
    "        self.calc_statistics()\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)# 이걸 glob으로 했던 것 같은데 확인\n",
    "        for profile in profiles:\n",
    "            if profile.startswith('.'): # glob으로 안하고 예외처리를 하셨네/ glob os.listdir 차이 확인\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names: # .으로 시작하는 파일 및 invalid한 파일 무시(??)ㅏ\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.data_dir, profile, file_name) \n",
    "                # (resized_data, 00003_male_Asian_54, mask1.jpg) _file_name이 아니라 file_name 호출\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split('_')\n",
    "                gender_label = getattr(self.GenderLabels, gender)\n",
    "                age_label = self.AgeGroup.map_label(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def calc_statistics(self):\n",
    "        has_statistics = self.mean is not None and self.std is not None\n",
    "        if not has_statistics:\n",
    "            print(\"[Warning] Calculating statistics... It can takes huge amounts of time depending on your CPU machine\")\n",
    "            sums = []\n",
    "            squared = []\n",
    "            for image_path in self.image_paths[:3000]: # 왜 3000까지만?\n",
    "                image = np.array(Image.open(image_path)).astype(np.int32)\n",
    "                sums.append(image.mean(axis = (0,1))) # axis에 값 두개 주는것이 어떤 의미인가\n",
    "                squared.append((image**2).mean(axis = (0,1)))\n",
    "\n",
    "            self.mean = np.mean(sums, axis = 0)/ 255\n",
    "            self.std = (np.mean(squared, axis = 0) - self.mean**2) ** 0.5 / 255\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transfrom = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.read_image(index)\n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "\n",
    "        image_transform = self.transform(image = np.array(image))['image']\n",
    "#         image_transform = self.transform(image=np.array(image))['image']\n",
    "        \n",
    "        return image_transform , multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def get_mask_label(self, index):\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index):\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index):\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    def read_image(self,index):\n",
    "        image_path = self.image_paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label):\n",
    "        return mask_label # * 6 gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label):\n",
    "        mask_label = (multi_class_label//6) % 3\n",
    "        gender_label  = (multi_class_label//3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image,mean,std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp,0,255).astype(np.uint8) # np.clip\n",
    "        return img_cp\n",
    "\n",
    "    def split_dataset(self):\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = torch.utils.data.random_split(self, [n_train, n_val])\n",
    "        return train_set, val_set\n",
    "\n",
    "    \n",
    "class MaskSplitByProfileDataset(MaskBaseDataset):\n",
    "    \"\"\"\n",
    "        train/val 나누는 기준을 이미지에 대해서 random이 아닌\n",
    "        사람(profile)을 기준으로 나눕니다.\n",
    "        구현은 val_ratio에 맞게 train/ val 나누는 것을 이미지 전체가 아닌 사람(profile)에 대해서 진행하여 indexing을 합니다.\n",
    "        이후 'split_dataset'에서 index에 맞게 Subset으로 dataset을 분기합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, mean = (.548, .504, .479), std = (.237, .247, .246), val_ratio =  0.2):\n",
    "        self.indices = defaultdict(list)\n",
    "        super().__init__(data_dir, mean, std, val_ratio)\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_profile(profiles, val_ratio):\n",
    "        length = len(profiles)\n",
    "        n_val = int(length * val_ratio)\n",
    "\n",
    "        val_indices = set(random.sample(range(length), k = n_val))\n",
    "        train_indices = set(range(length)) - val_indices\n",
    "\n",
    "        return {\n",
    "            \"train\" : train_indices,\n",
    "            \"val\" : val_indices\n",
    "        }\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        profiles = [profile for profile in profiles if not profile.startswith('.')]\n",
    "        split_profiles = self._split_profile(profiles, self.val_ratio)\n",
    "\n",
    "        cnt = 0\n",
    "        for phase, indices  in split_profiles.items():\n",
    "            for _idx in indices:\n",
    "                profile = profiles[_idx]\n",
    "                img_folder = os.path.join(self.data_dir, profile)\n",
    "                for file_name in os.listdir(img_folder):\n",
    "                    _file_name, ext = os.path.splitext(file_name)\n",
    "                    if _file_name not in self._file_names:\n",
    "                        continue\n",
    "\n",
    "                    img_path = os.path.join(self.data_dir, profile, file_name)\n",
    "                    mask_label = self._file_names[_file_name]\n",
    "\n",
    "                    id, gender, race, age = profile.split('_')\n",
    "                    gender_label = getattr(self.GenderLabels, gender)\n",
    "                    age_label = self.AgeGroup.map_label(age)\n",
    "\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(mask_label)\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "                    self.indices[phase].append(cnt)\n",
    "                    cnt += 1\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def split_dataset(self):\n",
    "        return [Subset(self, indices) for phase, indices in self.indices.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exceptional-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.560, .524,.501)\n",
    "std = (.233,.243,.247)\n",
    "\n",
    "transform = get_transforms(mean = mean, std = std)\n",
    "    \n",
    "# dataset = MaskBaseDataset(img_dir = img_dir)\n",
    "\n",
    "dataset = MaskSplitByProfileDataset(data_dir = img_dir)\n",
    "dataset.setup()\n",
    "train_dataset, val_dataset = dataset.split_dataset()\n",
    "\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = num_workers,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = num_workers,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "accumulation_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fitted-string",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](20/405)||training loss 0.1875 || training accuracy 87.89% || lr [0.0001]\n",
      "Epoch[0/5](40/405)||training loss 0.01453 || training accuracy 99.22% || lr [0.0001]\n",
      "Epoch[0/5](60/405)||training loss 0.009767 || training accuracy 99.06% || lr [0.0001]\n",
      "Epoch[0/5](80/405)||training loss 0.009246 || training accuracy 99.69% || lr [0.0001]\n",
      "Epoch[0/5](100/405)||training loss 0.002587 || training accuracy 99.77% || lr [0.0001]\n",
      "Epoch[0/5](120/405)||training loss 0.007518 || training accuracy 99.38% || lr [0.0001]\n",
      "Epoch[0/5](140/405)||training loss 0.004138 || training accuracy 99.69% || lr [0.0001]\n",
      "Epoch[0/5](160/405)||training loss 0.00396 || training accuracy 99.45% || lr [0.0001]\n",
      "Epoch[0/5](180/405)||training loss 0.0038 || training accuracy 99.69% || lr [0.0001]\n",
      "Epoch[0/5](200/405)||training loss 0.001672 || training accuracy 99.84% || lr [0.0001]\n",
      "Epoch[0/5](220/405)||training loss 0.002754 || training accuracy 99.77% || lr [0.0001]\n",
      "Epoch[0/5](240/405)||training loss 0.01049 || training accuracy 99.45% || lr [0.0001]\n",
      "Epoch[0/5](260/405)||training loss 0.002774 || training accuracy 99.77% || lr [0.0001]\n",
      "Epoch[0/5](280/405)||training loss 0.001051 || training accuracy 100.00% || lr [0.0001]\n",
      "Epoch[0/5](300/405)||training loss 0.0007146 || training accuracy 99.92% || lr [0.0001]\n",
      "Epoch[0/5](320/405)||training loss 0.0003552 || training accuracy 100.00% || lr [0.0001]\n",
      "Epoch[0/5](340/405)||training loss 0.0001463 || training accuracy 100.00% || lr [0.0001]\n",
      "Epoch[0/5](360/405)||training loss 0.0004724 || training accuracy 100.00% || lr [0.0001]\n",
      "Epoch[0/5](380/405)||training loss 0.0006361 || training accuracy 99.92% || lr [0.0001]\n",
      "Epoch[0/5](400/405)||training loss 0.0004386 || training accuracy 99.92% || lr [0.0001]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 99.66%, loss : 0.0047 ||best acc : 99.66%, best loss: 0.0047\n",
      "Epoch[1/5](20/405)||training loss 0.001301 || training accuracy 99.92% || lr [5e-05]\n",
      "Epoch[1/5](40/405)||training loss 0.0003587 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](60/405)||training loss 0.0001687 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](80/405)||training loss 0.0005902 || training accuracy 99.92% || lr [5e-05]\n",
      "Epoch[1/5](100/405)||training loss 0.0001563 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](120/405)||training loss 0.003087 || training accuracy 99.84% || lr [5e-05]\n",
      "Epoch[1/5](140/405)||training loss 0.0002774 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](160/405)||training loss 0.0005838 || training accuracy 99.92% || lr [5e-05]\n",
      "Epoch[1/5](180/405)||training loss 0.0001518 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](200/405)||training loss 0.001348 || training accuracy 99.84% || lr [5e-05]\n",
      "Epoch[1/5](220/405)||training loss 0.0005319 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](240/405)||training loss 0.0005852 || training accuracy 99.92% || lr [5e-05]\n",
      "Epoch[1/5](260/405)||training loss 0.0001105 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](280/405)||training loss 0.0001168 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](300/405)||training loss 0.0001488 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](320/405)||training loss 0.0001093 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](340/405)||training loss 0.0001443 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](360/405)||training loss 5.35e-05 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](380/405)||training loss 9.45e-05 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[1/5](400/405)||training loss 7.741e-05 || training accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 99.78%, loss : 0.0053 ||best acc : 99.78%, best loss: 0.0047\n",
      "Epoch[2/5](20/405)||training loss 0.0005713 || training accuracy 99.84% || lr [0.0]\n",
      "Epoch[2/5](40/405)||training loss 0.0005823 || training accuracy 99.92% || lr [0.0]\n",
      "Epoch[2/5](60/405)||training loss 0.0003994 || training accuracy 99.92% || lr [0.0]\n",
      "Epoch[2/5](80/405)||training loss 7.604e-05 || training accuracy 100.00% || lr [0.0]\n",
      "Epoch[2/5](100/405)||training loss 8.556e-05 || training accuracy 100.00% || lr [0.0]\n",
      "Epoch[2/5](120/405)||training loss 0.0001059 || training accuracy 100.00% || lr [0.0]\n",
      "Epoch[2/5](140/405)||training loss 0.0003668 || training accuracy 99.92% || lr [0.0]\n",
      "Epoch[2/5](160/405)||training loss 4.72e-05 || training accuracy 100.00% || lr [0.0]\n",
      "Epoch[2/5](180/405)||training loss 0.0006532 || training accuracy 99.92% || lr [0.0]\n",
      "Epoch[2/5](200/405)||training loss 7.708e-05 || training accuracy 100.00% || lr [0.0]\n",
      "Epoch[2/5](220/405)||training loss 0.0001401 || training accuracy 100.00% || lr [0.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a78545d42aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(),'results', model_name), exist_ok = True)\n",
    "\n",
    "counter =0 \n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    #train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels= train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim = -1)\n",
    "        loss = criterion(outs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (idx+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx+1) % train_log_interval == 0:\n",
    "            train_loss = loss_value/ train_log_interval\n",
    "            train_acc = matches / batch_size/ train_log_interval\n",
    "            current_lr = scheduler.get_last_lr()\n",
    "            wandb.log({\n",
    "                    \"Train_loss\": train_loss,\n",
    "                    \"Train_acc\": train_acc\n",
    "                })\n",
    "            print(\n",
    "                f'Epoch[{epoch}/{num_epochs}]({idx+1}/{len(train_loader)})||'\n",
    "                f'training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}'\n",
    "            )\n",
    "            \n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "    scheduler.step()\n",
    "    \n",
    "    #val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items= []\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim = -1)\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "        \n",
    "        val_loss = np.sum(val_loss_items)/ len(val_loader)\n",
    "        val_acc  = np.sum(val_acc_items)/ len(val_dataset)\n",
    "        wandb.log({\n",
    "                \"Valid_loss\": val_loss,\n",
    "                \"Valid_acc\": val_acc\n",
    "            })\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if val_acc > best_val_acc:\n",
    "            print('New best model for val accuracy! saving the model..')\n",
    "            now = time.localtime()\n",
    "            torch.save(model.state_dict(), f'results/{model_name}/{epoch:03}_accuracy_{val_acc:4.2%}_{now.tm_hour+9}:{now.tm_min}_mask.ckpt')\n",
    "            best_val_acc = val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter > patience:\n",
    "            print('Early stopping...')\n",
    "            break\n",
    "            \n",
    "        print(\n",
    "            f'[Val] acc : {val_acc:4.2%}, loss : {val_loss:4.2} ||'\n",
    "            f'best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20942<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-recipient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-specification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
